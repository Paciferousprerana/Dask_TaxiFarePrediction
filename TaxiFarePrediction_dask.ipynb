{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hawaiian-astronomy"
      },
      "source": [
        "# Implementation of Linear Regression on a Large Dataset Using Dask Library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "latin-seventh"
      },
      "source": [
        "## Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "civil-joyce"
      },
      "source": [
        "- understand how dask handles large dataset over pandas dataframe \n",
        "- perform exploratory data analysis on a large dataset (2 Million rows) using dask\n",
        "- implement linear regression model using dask library and make predictions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cm1iYi7ZD7Yq"
      },
      "source": [
        "## Problem Statement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlU7vlOfD7uk"
      },
      "source": [
        " Predict the taxi fare amount in New York city using Dask-ML."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the features the ' Dask_MP_dataset.csv' file that is provided for this miniproject varies slightly in terms of included features, as compared to the original dataset described above. Please proceed with the provided csv file."
      ],
      "metadata": {
        "id": "jox-Gb8RhEeb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbsLsOTejPIW"
      },
      "outputs": [],
      "source": [
        "#@title Install Dask dependencies and restart runtime\n",
        "!pip -qq install dask-ml\n",
        "!pip -qq install dask\n",
        "!pip -qq install dask[complete]\n",
        "!pip -qq install dask distributed\n",
        "!pip -qq install mimesis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKxO3msLjVB-"
      },
      "source": [
        "#### Importing Necessary Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tZDtdlmShI5"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import dask\n",
        "import dask.dataframe as dd\n",
        "import dask.array as da\n",
        "from dask_ml.linear_model import LinearRegression\n",
        "from dask_ml.model_selection import train_test_split\n",
        "from dask_ml.metrics import mean_squared_error, r2_score\n",
        "from dask.distributed import Client\n",
        "import time as time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns, matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from dask.distributed import Client, progress\n",
        "# client = Client()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "anjQfD2Imqpg"
      },
      "outputs": [],
      "source": [
        "#@title Download the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtkQh3Wtje4C"
      },
      "source": [
        "#### Read the dataset using dask library and compare the time of execution with pandas library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFyPyYzkyS0I"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "ddf = dd.read_csv('/content/Dask_MP_dataset.csv', dtype={'passenger_count': 'int64'})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ho9I-czijje-"
      },
      "source": [
        "#### Use pandas to read the dataset and compare the time taken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GtHtAhLvJZB"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "df_pd = pd.read_csv('/content/Dask_MP_dataset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vaXBh2aTZYM4"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "ddf.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFhWA9t11JhC"
      },
      "source": [
        "### Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZX1ryIsjqMu"
      },
      "source": [
        "#### Drop the unnecessary columns. Also drop the duplicate rows and the rows having null values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oY4VbXnyy7E0"
      },
      "outputs": [],
      "source": [
        "ddf = ddf.drop([\"key\", \"Unnamed: 0\"],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5C8YkabI1N4l"
      },
      "outputs": [],
      "source": [
        "# Drop duplicate rows\n",
        "%%time\n",
        "ddf = ddf.drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2uYv6q0FZtYO"
      },
      "outputs": [],
      "source": [
        "# ddf['pickup_datetime'] = dask.dataframe.to_datetime(ddf['pickup_datetime'])\n",
        "# ddf['year'] = ddf['pickup_datetime'].dt.year\n",
        "# ddf.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZTAo8LafjU7",
        "outputId": "74a597ca-f7b6-4913-dd4d-5b135781e5f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 6.04 ms, sys: 148 µs, total: 6.18 ms\n",
            "Wall time: 6.88 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "ddf = ddf.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trDd9NJTF61J"
      },
      "outputs": [],
      "source": [
        "# Drop duplicate rows in pandas dataframe\n",
        "%%time\n",
        "df_pd = df_pd.drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MlAw0IP3F6oc"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "df_pd = df_pd.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLOBvChhMOzy"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "ddf.groupby(\"passenger_count\").fare_amount.mean().compute()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bY6cmDEMO-X",
        "outputId": "fca18cf0-e7c0-408a-d46f-f759c3697b1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 33.6 ms, sys: 67 µs, total: 33.6 ms\n",
            "Wall time: 39.6 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "passenger_count\n",
              "0        8.862578\n",
              "1       11.224824\n",
              "2       11.819826\n",
              "3       11.533967\n",
              "4       11.747775\n",
              "5       11.208924\n",
              "6       12.158254\n",
              "9      104.000000\n",
              "208      3.300000\n",
              "Name: fare_amount, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "%%time\n",
        "df_pd.groupby(\"passenger_count\").fare_amount.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hui7_jEXNixT"
      },
      "outputs": [],
      "source": [
        "%%time \n",
        "ddf[[\"fare_amount\"]].mean().compute()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0GZOsyzWNsCy"
      },
      "outputs": [],
      "source": [
        "%%time \n",
        "df_pd[[\"fare_amount\"]].mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4KUGEAlju_J"
      },
      "source": [
        "#### Visualize the target variable, i.e., `fare_amount` to study the fare distribution, using a histogram density plot. Analyze the fare_amount distribution, try to visualize it for a range of [0, 60].\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WpvOEUW01WI_"
      },
      "outputs": [],
      "source": [
        "#exploring data\n",
        "\n",
        "def plot_dist(series=ddf[\"fare_amount\"], title = \"Fare Distribution\"):\n",
        "  sns.histplot(series, kde=True, stat='density',discrete=True)\n",
        "  sns.despine()\n",
        "  plt.title(title)\n",
        "  sns.histplot(series, kde=True, stat='density',discrete=True)\n",
        "  sns.despine()\n",
        "  plt.title(title);\n",
        "  plt.show();\n",
        "  plt.show()\n",
        "plot_dist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEtm-YkTM7iK"
      },
      "outputs": [],
      "source": [
        "#dropping absurd values and plotting fare amount in the range [0, 60]\n",
        "ddf = ddf[ddf.fare_amount.between(0,60)]\n",
        "plot_dist(ddf.fare_amount)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvPfB3yKiVQG"
      },
      "source": [
        "#### Observe the number of workers and cores running in your machine\n",
        "\n",
        "Initialize a client and observe how many workers are working and the number of cores utilizing for the given data set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O85yDn3kRErR"
      },
      "outputs": [],
      "source": [
        "# #Initializing a client\n",
        "# client = Client(processes=False)\n",
        "# client"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFmt8ZxPj9Oh"
      },
      "source": [
        "### EDA based on Time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8cNhcLukCwi"
      },
      "source": [
        "#### Extract day of the week (dow), hour, month and year from `pickup_datetime`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZUu0gSEgKWm"
      },
      "outputs": [],
      "source": [
        "# pickup_datetime feature\n",
        "\n",
        "def extract_time_features(ddf):\n",
        "    timezone_name = 'America/New_York'\n",
        "    time_column = \"pickup_datetime\"\n",
        "    ddf.index = pd.to_datetime(ddf[time_column])\n",
        "    #ddf.index = ddf.index.tz_convert(timezone_name)\n",
        "    ddf[\"dow\"] = ddf.index.weekday\n",
        "    ddf[\"hour\"] = ddf.index.hour\n",
        "    ddf[\"month\"] = ddf.index.month\n",
        "    ddf[\"year\"] = ddf.index.year\n",
        "    return ddf.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4qP_G40gaX6"
      },
      "outputs": [],
      "source": [
        "ddf = extract_time_features(ddf.compute())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pAxBjYaCziQc"
      },
      "outputs": [],
      "source": [
        "ddf.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQlZJuvfkHmx"
      },
      "source": [
        "#### Plot the taxi trip by hour of the day\n",
        "\n",
        "* Partition the data into segments using `dask.from_pandas()`\n",
        "\n",
        "* Plot the taxi trip for hour of the day."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dcDhog9ntzYn"
      },
      "outputs": [],
      "source": [
        "ddf = dd.from_pandas(ddf, npartitions=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r06GIu7AuZ8N"
      },
      "outputs": [],
      "source": [
        "type(ddf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3GzEYwzgiwq"
      },
      "outputs": [],
      "source": [
        "# taxi trip repartition by hour of the day\n",
        "\n",
        "sns.catplot(x=\"hour\", kind=\"count\", palette=\"icefire\", data=ddf.compute(), height=5, aspect=3);\n",
        "sns.despine()\n",
        "plt.title('Hour of Day');\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjSKhr4HkNL3"
      },
      "source": [
        "#### Plot the taxi trip repartition by day of the week (dow)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mf3fe9hnRFnL"
      },
      "outputs": [],
      "source": [
        "# taxi trip repartition by day of the week\n",
        "\n",
        "sns.catplot(x=\"dow\", kind=\"count\", palette=\"icefire\", data=ddf.compute(), height=5, aspect=3);\n",
        "sns.despine()\n",
        "plt.title('Day of Week');\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ez8XDkvXkSr7"
      },
      "source": [
        "#### Draw a plot between the target variable and passenger count and analyze it. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATLNkBHqYrG_"
      },
      "outputs": [],
      "source": [
        "#passenger count feature\n",
        "\n",
        "sns.catplot(x=\"passenger_count\", y=\"fare_amount\", palette=\"icefire\", data=ddf.compute(), kind=\"bar\", aspect=3)\n",
        "sns.despine()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pGGhg1rkXl3"
      },
      "source": [
        "#### Draw a plot between the target variable and hour and analyze it. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DVhX3JZYytp"
      },
      "outputs": [],
      "source": [
        "#fare amount by hour\n",
        "\n",
        "sns.catplot(x=\"hour\", y=\"fare_amount\", palette=\"icefire\", data=ddf.compute(), kind=\"bar\", aspect=3)\n",
        "sns.despine()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnhM0X0MkgOx"
      },
      "source": [
        "#### Compute the Haversine distance between samples\n",
        "\n",
        "* Convert the latitude and longitude co-rodinates to radians\n",
        "\n",
        "* Calculate the Haversine distance\n",
        "\n",
        "  [haversine_distances](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.haversine_distances.html)\n",
        "\n",
        "* Add the \"distance\" feature to the dataset and plot its distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4oLk2DtR-kP"
      },
      "outputs": [],
      "source": [
        "# Distance feature (given formula)\n",
        "\n",
        "def haversine_distance(ddf,\n",
        "                       start_lat=\"start_lat\",\n",
        "                       start_lon=\"start_lon\",\n",
        "                       end_lat=\"end_lat\",\n",
        "                       end_lon=\"end_lon\"):\n",
        "    \n",
        "    # Calculate the great circle distance between two points \n",
        "    #on the earth (specified in decimal degrees).\n",
        "       \n",
        "    # Vectorized version of the haversine distance for pandas df\n",
        "    #Computes distance in kms\n",
        "    \n",
        "    lat_1_rad, lon_1_rad = np.radians(ddf[start_lat].astype(float)), np.radians(ddf[start_lon].astype(float))\n",
        "    lat_2_rad, lon_2_rad = np.radians(ddf[end_lat].astype(float)), np.radians(ddf[end_lon].astype(float))\n",
        "    dlon = lon_2_rad - lon_1_rad\n",
        "    dlat = lat_2_rad - lat_1_rad\n",
        "\n",
        "    a = np.sin(dlat / 2.0) ** 2 + np.cos(lat_1_rad) * np.cos(lat_2_rad) * np.sin(dlon / 2.0) ** 2\n",
        "    c = 2 * np.arcsin(np.sqrt(a))\n",
        "    haversine_distance = 6371 * c\n",
        "    return haversine_distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WGnk96MsrFI"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "ddf[\"distance\"] = haversine_distance(ddf, \n",
        "                                     start_lat=\"pickup_latitude\", start_lon=\"pickup_longitude\",\n",
        "                                     end_lat=\"dropoff_latitude\", end_lon=\"dropoff_longitude\"\n",
        "                                     )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VaKyX4pQYeNF"
      },
      "outputs": [],
      "source": [
        "ddf.distance.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6RHj-NePYi3y"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "plot_dist(series=ddf[ddf.distance<50].distance, title = \"Distance distribution\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEm1VCEhkmxy"
      },
      "source": [
        "### Correlation between distance and fare amount"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8C5jkzcZOxO"
      },
      "outputs": [],
      "source": [
        "# Correlation between fare_amount and distance\n",
        "\n",
        "sns.scatterplot(x=\"distance\", y=\"fare_amount\", palette=\"icefire\",data=ddf[ddf.distance < 80].compute().sample(10000))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI_BrhbAksa4"
      },
      "source": [
        "### Preparing dataset for model implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eBdsM-ue0PAU"
      },
      "outputs": [],
      "source": [
        "# Read the dataset to prepare for training\n",
        "\n",
        "data_train = ddf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxy-7gBSRWGP"
      },
      "source": [
        "### Removing outliers from training set Based on Coordinates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rJQ5ecOk_Q8"
      },
      "source": [
        "#### Remove the outliers using the given latitude and longitude features from the dataset. We need to analyze the data of taxi within New York City.\n",
        "\n",
        "Given the co-ordinates of New York city are Latitude: 40.7128° and Longitude: -74.0060°. We can include the pickup and drop off points such that there left and right value mean will be the given co-ordinate value. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MsqHSsooRi4V"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "data_train = data_train[data_train[\"pickup_latitude\"].between(left = 40, right = 42 )]\n",
        "data_train = data_train[data_train[\"pickup_longitude\"].between(left = -74.3, right = -72.9 )]\n",
        "data_train = data_train[data_train[\"dropoff_latitude\"].between(left = 40, right = 42 )]\n",
        "data_train = data_train[data_train[\"dropoff_longitude\"].between(left = -74, right = -72.9 )]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhjCIcP4z6HM"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "data_train[\"distance\"] = haversine_distance(data_train, \n",
        "                                      start_lat=\"pickup_latitude\", start_lon=\"pickup_longitude\",\n",
        "                                      end_lat=\"dropoff_latitude\", end_lon=\"dropoff_longitude\"\n",
        "                                     )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVKVLO_wz_yO"
      },
      "outputs": [],
      "source": [
        "data_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0wKLJpOlGX2"
      },
      "source": [
        "#### Divide the data into train and test splits with X as feature variables and y as target variable\n",
        "\n",
        "* Divide data into train test split with 70-30 ratio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3asw71jH1C7V"
      },
      "outputs": [],
      "source": [
        "X = data_train.drop([\"fare_amount\", \"pickup_datetime\"], axis=1)\n",
        "y = data_train[[\"fare_amount\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhvvQ7jdg-4I"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bAorNHLaNauK"
      },
      "outputs": [],
      "source": [
        "type(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rvbe9ZtUoMp"
      },
      "outputs": [],
      "source": [
        "type(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5_q4A_oOPBD"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.compute()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "be5xWyYcOS36"
      },
      "outputs": [],
      "source": [
        "y_train = y_train.compute()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hb4qVD4GgqhJ"
      },
      "outputs": [],
      "source": [
        "#fit the model\n",
        "lr = LinearRegression()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4AQ8kJ-K0HCM"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "lr.fit(X_train.values, y_train.values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZr9OMdElQcb"
      },
      "source": [
        "#### Predict the test data and calculate the mean squared error and r2 score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqGNMROAWZgm"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "X_test = X_test.compute()\n",
        "y_pred = lr.predict(X_test.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdRoc9cv2E2-"
      },
      "outputs": [],
      "source": [
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHDebnxC1LCG"
      },
      "outputs": [],
      "source": [
        "y_test = y_test.to_dask_array(lengths=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-iLrP4h2uDC"
      },
      "outputs": [],
      "source": [
        "y_test = y_test.reshape(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4ImLCty2-xP"
      },
      "outputs": [],
      "source": [
        "y_test.compute()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_FetEGcW8_M"
      },
      "outputs": [],
      "source": [
        "# Mean squared error\n",
        "%%time\n",
        "mean_squared_error(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDEKGa5Q3Xla"
      },
      "outputs": [],
      "source": [
        "# R2_Score\n",
        "%%time\n",
        "r2_score(y_test, y_pred)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}